# BayesianCNN

Gaussian processes can describe the distribution and variation of random variables. In neural network training, transforming traditional individual weights into random variables following a Gaussian distribution allows modeling the mean and covariance of the weights. If there is prior knowledge or historical data available, they can be used to estimate $\mu$ and $\Sigma$. For example, if the relationship between the neural network's structure and input-output is known, these can be used to calculate the expected values for each hyperparameter. Alternatively, if there is training and testing data, they can be used to compute the mean and variance of each hyperparameter on the training and testing sets. Literature suggests that a neural network with weights following a normal distribution outputs a Gaussian process.

Applying Gaussian processes to convolutional neural networks in image classification tasks can enhance the efficiency and accuracy of network training. I will explore the feasibility of this approach in image classification tasks using a simple neural network and compare it with traditional methods. Evaluation metrics such as accuracy, precision, recall, F1 score, etc., will be considered, and the [Oxford-IIIT Pet Dataset4]('https://www.kaggle.com/datasets/samuelcortinhas/cats-and-dogs-image-classification/') will be used as the dataset.
